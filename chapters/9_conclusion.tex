%!TEX ROOT=../dissertation.tex

\chapter{Conclusion}
\label{chap:conclusion}
This study outlined current challenges and motivations—building automated support for fact‑checking.
Most solutions rely on transformers, the SOTA for almost every NLP task.
The paradigm is shifting from \textit{fine‑tuning} pre‑trained encoders/decoders to \textit{prompting} and few‑shotting instruction‑tuned LLMs, which impacts this dissertation and requires modernizing prior work.

So far, we have collected several datasets—most notably \FCZ and \CTK—deployed a working fact‑checking pipeline, and released trained models for reuse.

Next, we aim to establish claim generation and its model‑based metrics, conclude ongoing model training and data collection (Czech, English, Polish, Slovak), and propose updated end‑to‑end solutions leveraging modern LLMs.

The preceding chapters summarized what has been done, why it matters, the surrounding context, and the likely next steps.