%!TEX ROOT=../ctutest.tex

\chapter{State of the Art}
This chapter will first describe the originally popular models for NLP such as BERT and its relatives and then the paradigm shift from pre-train+fine-tune frameworks to LLMs (possibly few-shot learned or adapted with LoRA). 

\todo{Citations: Lora, daniil, Bert paper, GPT4 debiln√≠ report}
\label{chap:sota}
\section{Pre-train + Fine-tune}
\label{sec:pretrain}