%!TEX ROOT=../ctutest.tex

\chapter{Conclusion}
\label{chap:conclusion}
In this study, I have presented my current challenges and their motivation -- a desire for an automated scheme to assist fact-checking.
The solutions are being proposed in other literature and rely mostly on transformers, which is the current state of the art for nearly every NLP task.
The transformer usage paradigm is shifting (from the approach of \textit{fine-tuning} a \textit{pre-trained} transformer to \textit{prompting} or \textit{few-shotting} a Large Language Model), which will impact my dissertation and also yield new challenges in modernizing our previous work.

So far, numerous datasets, most notably the \FCZ and \CTK, have been collected, a working fact-checking pipeline was deployed on them, and the models we trained were published for further use.

Other tasks are to be established among the scientific public, importantly the claim generation and its model-based metrics, ongoing research such as the claim generation model training, collection of additional data in Czech, English, Polish, and Slovak is to be concluded, and new solutions for the whole problem of automated fact-checking are to be proposed, utilizing the new SOTA methods, such as the Large Language Models.

The point of the precedent chapters of the study was to give insights on what has been done so far, what is its value, what is the context in which this is happening, and what are the likely next steps in the future of my research.